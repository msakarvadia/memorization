{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "240107bb-bda6-4cb3-b373-99496185b06e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Set Up/Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990856d1-5032-4f5f-8d4a-84ff2f0a3887",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692346f5-61b2-435c-b0a2-b2e5833181fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# conda activate \"/pscratch/sd/m/mansisak/memorization/env/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9512f68a-39fd-4e37-825d-b2415fa10198",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0039350a-fa65-49c0-acb7-b763c9aa5198",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65bfcf8-bc73-49b7-98fe-ebad53b40ca8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from transformers import AutoModelForCausalLM\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "### TODO: figure out automatically\n",
    "# device = \"cpu\"\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bd0961-4ef1-4ed8-952b-55c43e12cce8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load in Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c93588-3a75-49b6-bef8-41da12d99c8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_edited_model_paths(parent_path):\n",
    "    \n",
    "    total_exp = 0\n",
    "    for model_name in ['pythia-6.9b-deduped', 'pythia-2.8b-deduped']:\n",
    "        y_idx = 0\n",
    "        for step in [36000, 72000, 108000, 143000]:\n",
    "            for loc_method in [\n",
    "                  \"act\",\n",
    "                  \"hc\",\n",
    "                  \"slim\",\n",
    "                  \"durable\",\n",
    "                  \"durable_agg\",\n",
    "                  \"random\",\n",
    "                  \"random_greedy\",\n",
    "                  \"greedy\",\n",
    "              ]:\n",
    "                \n",
    "                for ratio in [0.00001, 0.0001, 0.001, 0.01, 0.05, 0.1, 0.25, 0.3]:\n",
    "                    result_path = f\"{parent_path}{step}/EleutherAI_edit/{loc_method}/mem/{ratio}\"\n",
    "                    if loc_method not in [\"random\", \"random_greedy\"]:\n",
    "                        if ratio >= 0.1:\n",
    "                            continue\n",
    "\n",
    "                    # this ratio is too small for neuron-level methods\n",
    "                    if loc_method in [\"zero\", \"hc\", \"ig\", \"slim\", \"act\"]:\n",
    "                        if ratio <= 0.0001:\n",
    "                            continue\n",
    "\n",
    "                    if loc_method in [\"greedy\"]:\n",
    "                        if ratio > 0.00001:\n",
    "                            continue\n",
    "                            \n",
    "                    ######\n",
    "                    if loc_method in [\"greedy\", \"durable\", \"durable_agg\",\"act\"]:\n",
    "                        model_path = f'{result_path}/{model_name}'\n",
    "                        total_exp += 1\n",
    "\n",
    "                    if loc_method in [\"slim\", \"hc\"]:\n",
    "                        for epochs in [1, 10, 20]:\n",
    "                            total_exp += 1\n",
    "                            model_path = f'{result_path}/{epochs}/1000/0.1/0.1/{model_name}'                      \n",
    "\n",
    "                    if loc_method in [\"random\", \"random_greedy\"]:\n",
    "                        for epochs in [1, 10, 20]:\n",
    "                            total_exp += 1\n",
    "                            model_path = f'{result_path}/{epochs}/0.1/0.9/0.0005/{model_name}'\n",
    "                    if os.path.isfile(model_path):\n",
    "                        print(\"edited model exists:\", model_path)\n",
    "                    else:\n",
    "                        print(\"edited model doesn't exist yet: \", model_path)\n",
    "\n",
    "    print(\"total_expeirments: \", total_exp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1865793f-b745-4f7c-8532-4591860afc1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# parent_path = \"/pscratch/sd/m/mansisak/memorization/model_ckpts/\"\n",
    "parent_path = \"/pscratch/sd/m/mansisak/memorization/model_ckpts/\"\n",
    "\n",
    "print_edited_model_paths(parent_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c036efd-bbcd-4a48-b8c6-b2f74155fd00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Example of how to load in a model:\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"EleutherAI/pythia-2.8b-deduped\",\n",
    "    torch_dtype=torch.float16,\n",
    "    # torch_dtype=torch.float32,\n",
    "    device_map=device\n",
    ")\n",
    "\n",
    "# sd_path = '/pscratch/sd/m/mansisak/memorization/model_ckpts/old_run/143000/EleutherAI_edit/random_greedy/mem/0.001/20/0.1/0.9/0.0005/pythia-2.8b-deduped'\n",
    "sd_paths = dict(\n",
    "    unedited = None,\n",
    "    good_edit = \"/pscratch/sd/m/mansisak/memorization/model_ckpts/143000/EleutherAI_edit/random_greedy/mem/0.001/20/0.1/0.9/0.0005/pythia-2.8b-deduped\",\n",
    "    bad_edit = \"/pscratch/sd/m/mansisak/memorization/model_ckpts/143000/EleutherAI_edit/random/mem/0.1/20/0.1/0.9/0.0005/pythia-2.8b-deduped\",\n",
    ")\n",
    "\n",
    "# choose which model to load\n",
    "use_model = \"unedited\"\n",
    "# use_model = \"good_edit\"\n",
    "# use_model = \"bad_edit\"\n",
    "sd_path = sd_paths.get(use_model)\n",
    "\n",
    "if sd_path is not None:\n",
    "    sd = torch.load(sd_path, map_location=device)[\"model_state_dict\"]\n",
    "    if \"random\" in sd_path:\n",
    "        for k in sd:\n",
    "            if \"4h\" in k:\n",
    "                #rint(sd[k].shape)\n",
    "                #rint(k)\n",
    "                sd[k] = sd[k].T\n",
    "    model.load_state_dict(sd, assign=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff41486-4b7d-4042-b023-c536b52d6ac0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!ls -ls /pscratch/sd/m/mansisak/memorization/model_ckpts/143000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f1b8eb-b502-4c11-a2a8-0113053b1340",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b04ce0-d74c-472a-be25-eee922642533",
   "metadata": {},
   "source": [
    "# Load in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de5bd3e-0a01-4e83-b410-f1493ad58aa5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "random_data = torch.load(\"/pscratch/sd/m/mansisak/memorization/src/data/pythia_mem_data/pile_random_batch.pt\")\n",
    "random_data_pile = torch.reshape(random_data[0:2040], (3264, 80))#.to(device)\n",
    "\n",
    "# random_data = random_data_pile[0:1632]\n",
    "# random_subset_data = random_data_pile[0:10] # for testing purposes\n",
    "random_subset_data = random_data_pile[0:128] # for loss landscapes (~ 7% of the data)\n",
    "random_subset_data = random_subset_data.to(device)\n",
    "random_subset_dataloader = DataLoader(random_subset_data, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0195c8-f054-4c1c-919f-46b75f8a6393",
   "metadata": {},
   "source": [
    "# Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701138ae-5dde-401e-988f-6aa8eb3a899d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def perplexity(model, dataloader):\n",
    "    avg_metric = 0\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        with torch.no_grad():\n",
    "            model_output = model(batch, labels=batch)\n",
    "        loss = model_output.loss\n",
    "        loss_exp = torch.exp(loss)\n",
    "        if torch.isinf(loss_exp):\n",
    "            print(f\"Skipping invalid loss...\")\n",
    "            print(f\"    {i=}, loss={loss.item()}, exp(loss)={torch.exp(loss).item()}\")\n",
    "        avg_metric += loss_exp\n",
    "        # print(loss.item())\n",
    "    return avg_metric / len(dataloader)\n",
    "\n",
    "\n",
    "def perplexity_criterion(model_output, targets=None):\n",
    "    loss = model_output.loss\n",
    "    return torch.exp(loss)\n",
    "\n",
    "\n",
    "def average_loss(model, dataloader):\n",
    "    avg_metric = 0\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        with torch.no_grad():\n",
    "            model_output = model(batch, labels=batch)\n",
    "        loss = model_output.loss\n",
    "        avg_metric += loss\n",
    "        # print(loss.item())\n",
    "    return avg_metric / len(dataloader)\n",
    "\n",
    "\n",
    "from torch.nn import CrossEntropyLoss\n",
    "def loss_criterion(model_output, inputs):\n",
    "    # Shift so that tokens < n predict n\n",
    "    shift_labels = inputs[..., 1:].contiguous()\n",
    "    shift_logits = model_output.logits[..., :-1, :].contiguous()\n",
    "    # Calculate per-token loss\n",
    "    loss_fct = CrossEntropyLoss(reduction=\"none\")\n",
    "    loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
    "    # Resize and average loss per sample\n",
    "    loss_per_sample = loss.view(shift_logits.size(0), shift_logits.size(1)).mean(axis=1)\n",
    "    return (loss_per_sample).mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670be195-92ae-4270-bdc0-860a792b39b2",
   "metadata": {},
   "source": [
    "# Loss Landscape stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603ae303-9c10-43c8-939c-55aade290580",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pyhessian import hessian\n",
    "from pyhessian.utils import normalization\n",
    "import copy\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d01b6d-a8de-4d80-b865-3d50d636d5ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_params(model_orig, model_perb, direction, alpha):\n",
    "    for m_orig, m_perb, d in zip(\n",
    "        model_orig.parameters(), model_perb.parameters(), direction\n",
    "    ):\n",
    "        m_perb.data = m_orig.data + alpha * d\n",
    "    return model_perb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0b6538-93e4-405f-8518-ee4f96e4b43d",
   "metadata": {},
   "source": [
    "## 2D random directions (loss-landscapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7b2366-34b9-4dea-b2d3-03bc5aec55d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# libraries\n",
    "import copy\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "from tqdm import tqdm\n",
    "\n",
    "# matplotlib.rcParams['figure.figsize'] = [18, 12]\n",
    "\n",
    "import loss_landscapes\n",
    "import loss_landscapes.metrics\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebac614f-c4b7-4be2-9f70-ed7099ae61ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from loss_landscapes.metrics import Metric\n",
    "from loss_landscapes.model_interface.model_wrapper import ModelWrapper\n",
    "\n",
    "class CustomLoss(Metric):\n",
    "    \"\"\" Computes a specified loss function over specified input-output pairs. \"\"\"\n",
    "    def __init__(self, loss_fn, dataloader: torch.Tensor):\n",
    "        super().__init__()\n",
    "        self.loss_fn = loss_fn\n",
    "        self.dataloader = dataloader\n",
    "\n",
    "    def __call__(self, model_wrapper: ModelWrapper) -> float:\n",
    "        # loop over batches \n",
    "        loss = 0\n",
    "        for batch in self.dataloader:\n",
    "            loss += self.loss_fn(model_wrapper.forward(batch), batch).item()\n",
    "        return loss / len(self.dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e7010c-677e-4467-9b22-a8585decaea4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# data that the evaluator will use when evaluating loss\n",
    "metric = CustomLoss(loss_criterion, random_subset_dataloader)\n",
    "metric(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa44fc4d-1c0e-446b-a8b7-582cb6684e59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    model_perb = copy.deepcopy(model)\n",
    "    model_perb.eval()\n",
    "    \n",
    "    # model = model.to(\"cpu\")\n",
    "    model_perb = model_perb.to(device)\n",
    "    model_perb = model_perb.to(torch.float32)\n",
    "    # model = model.to(device)\n",
    "    # model = model.to(torch.float32)\n",
    "    print(f\"{model_perb.dtype=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed6e448-2e46-4b93-815b-22fef5623cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SEED = 543\n",
    "STEPS = 21 \n",
    "DIST = 1\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "data_matrix = loss_landscapes.random_plane(\n",
    "    model_perb, metric, \n",
    "    DIST, STEPS, \n",
    "    normalization='filter', \n",
    "    deepcopy_model=False,\n",
    "    device=device,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156c6b4a-2893-4bbc-a2da-d88e620dd6fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_data = random_subset_data.size()[0]\n",
    "save_as_npy = f\"loss_landscape_files/data_matrix_{use_model}_random_data_{n_data}_steps_{STEPS}_distance_{DIST}_seed_{SEED}.npy\"\n",
    "if not os.path.exists(os.path.dirname(save_as_npy)):\n",
    "    os.makedirs(os.path.dirname(save_as_npy))\n",
    "np.save(save_as_npy, data_matrix)\n",
    "print(f\"[+] {save_as_npy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ad5b4a-ff12-4aa5-b9cc-dd1e5ccfaab9",
   "metadata": {},
   "source": [
    "## plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462375b5-aa65-4fa6-bae7-415423f32b0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "X = np.array([[j for j in range(STEPS)] for i in range(STEPS)])\n",
    "Y = np.array([[i for _ in range(STEPS)] for i in range(STEPS)])\n",
    "ax.plot_surface(X, Y, data_matrix, rstride=1, cstride=1, cmap='inferno', edgecolor='none')\n",
    "# ax.set_title(f'Surface Plot of Loss Landscape ({use_model})')\n",
    "plt.suptitle(f'Loss Landscape ({use_model})', fontweight=\"bold\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab24268f-f221-432a-bf2e-d090d0094593",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for creating a responsive plot \n",
    "# %matplotlib widget\n",
    "\n",
    "# importing required libraries \n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "# Reshape the data_matrix into a 41x41 grid for plotting\n",
    "Z = data_matrix.reshape((STEPS, STEPS))\n",
    "\n",
    "# Generate X and Y coordinates (41x41 grid)\n",
    "x = np.linspace(-DIST/2, DIST/2, STEPS)  \n",
    "y = np.linspace(-DIST/2, DIST/2, STEPS)\n",
    "print(x)\n",
    "print(y)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "# Plot the 3D surface with filled colors\n",
    "surf = ax.plot_surface(X, Y, Z, cmap='inferno_r', edgecolor='none')\n",
    "\n",
    "# Add a color bar for reference\n",
    "# fig.colorbar(surf, ax=ax, shrink=0.5, aspect=5)\n",
    "\n",
    "# Set labels\n",
    "# plt.xticks(fontsize=8)\n",
    "# plt.yticks(fontsize=8)\n",
    "\n",
    "# ax.set_xlabel('$\\delta_{1}$', fontsize=18, fontweight=\"bold\")\n",
    "# ax.set_ylabel('$\\delta_{2}$', fontsize=18, fontweight=\"bold\")\n",
    "# ax.set_zlabel('Loss', fontsize=18, rotation=90)\n",
    "\n",
    "ax.set_title(f'Loss Landscape ({use_model})', fontweight=\"bold\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "save_as_png = f\"loss_landscape_files/loss_landscape_{use_model}_random_data_{n_data}_steps_{STEPS}_distance_{DIST}_seed_{SEED}.png\"\n",
    "plt.savefig(save_as_png, dpi=600)\n",
    "print(f\"[+] {save_as_png}\")\n",
    "      \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c53f50-7a22-46a9-9f4c-ac113647e651",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1255df-c271-4a0f-8df5-772a53d9b22e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79549497-4659-4606-8d29-87c59fa00c12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "memorization",
   "language": "python",
   "name": "memorization"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
